{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN26cav5XTW2y3LVLrYCA43",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanu26062006/Assignment-2/blob/main/Task34567.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NdpsSeik7oYG",
        "outputId": "b22284ca-6157-4a8e-95dc-ef153812812f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 3: Data Preparation ---\n",
            "'/content/fra.txt' already exists in 'data/'. Skipping download.\n",
            "Number of sentence pairs loaded: 20000\n",
            "English (Input) Vocabulary Size: 3275\n",
            "French (Target) Vocabulary Size: 5498\n",
            "Max English (Encoder) sequence length: 7\n",
            "Max French (Decoder) sequence length: 17\n",
            "\n",
            "--- Data Preparation Summary ---\n",
            "Shape of Encoder Input Data: (20000, 7)\n",
            "Shape of Decoder Input Data: (20000, 17)\n",
            "Shape of Decoder Target Data: (20000, 17)\n",
            "\n",
            "--- Task 4: Building and Training Model (Basic Encoder-Decoder) ---\n",
            "\n",
            "Basic Encoder-Decoder Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │    \u001b[38;5;34m327,500\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │    \u001b[38;5;34m549,800\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m365,568\u001b[0m │ encoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m365,568\u001b[0m │ decoder_embeddin… │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m1,412,986\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m5498\u001b[0m)             │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">327,500</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">549,800</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ encoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ decoder_embeddin… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,412,986</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">5498</span>)             │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,021,422\u001b[0m (11.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,021,422</span> (11.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,021,422\u001b[0m (11.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,021,422</span> (11.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the basic model for 20 epochs...\n",
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 916ms/step - accuracy: 0.5224 - loss: 5.3841 - val_accuracy: 0.2366 - val_loss: 3.7448\n",
            "Epoch 2/20\n",
            "\u001b[1m 89/250\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 826ms/step - accuracy: 0.2379 - loss: 3.4016"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
        "from tensorflow.keras.layers import Attention # Keras's built-in Attention layer\n",
        "\n",
        "# --- Global Configuration Parameters (can be adjusted) ---\n",
        "NUM_SAMPLES = 20000\n",
        "BATCH_SIZE = 64\n",
        "LATENT_DIM = 256 # Dimensionality of the LSTM's hidden state\n",
        "EMBEDDING_DIM = 100 # Dimensionality of word embeddings\n",
        "EPOCHS = 20 # Train for at least 10 epochs (as per Task 4)\n",
        "\n",
        "# --- Data Path and File Names ---\n",
        "DATA_DIR = \"data\"\n",
        "ZIP_FILE_NAME = \"fra-eng.zip\"\n",
        "TEXT_FILE_NAME = \"/content/fra.txt\"\n",
        "DATA_URL = \"http://www.manythings.org/anki/\" + ZIP_FILE_NAME\n",
        "\n",
        "# Initialize variables to avoid NameError if Task 3 fails\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_vocab_size = 0\n",
        "target_vocab_size = 0\n",
        "max_encoder_seq_length = 0\n",
        "max_decoder_seq_length = 0\n",
        "encoder_input_data = np.array([])\n",
        "decoder_input_data = np.array([])\n",
        "decoder_target_data = np.array([])\n",
        "input_tokenizer = None\n",
        "target_tokenizer = None\n",
        "input_word_index = {}\n",
        "target_word_index = {}\n",
        "reverse_input_word_index = {}\n",
        "reverse_target_word_index = {}\n",
        "model = None # For the basic model from Task 4\n",
        "model_with_attention = None # For the attention model from Task 6\n",
        "history = None # For training history from Task 4 or Task 6\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Task 3: Data Preparation for Sequence Learning ---\n",
        "# ==============================================================================\n",
        "print(\"--- Task 3: Data Preparation ---\")\n",
        "\n",
        "# 1. Download and Extract Dataset\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    os.makedirs(DATA_DIR)\n",
        "\n",
        "data_file_path = os.path.join(DATA_DIR, TEXT_FILE_NAME)\n",
        "\n",
        "if not os.path.exists(data_file_path):\n",
        "    print(f\"Downloading {ZIP_FILE_NAME} from {DATA_URL}...\")\n",
        "    try:\n",
        "        response = requests.get(DATA_URL)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors\n",
        "        with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
        "            z.extract(TEXT_FILE_NAME, DATA_DIR)\n",
        "        print(f\"Extracted {TEXT_FILE_NAME} to {DATA_DIR}/\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading data: {e}\")\n",
        "        print(\"Please ensure you have an active internet connection or manually download and place 'fra.txt' in a 'data' folder.\")\n",
        "    else:\n",
        "        if not os.path.exists(data_file_path):\n",
        "             print(f\"File '{TEXT_FILE_NAME}' not found after extraction. Please check the zip content.\")\n",
        "else:\n",
        "    print(f\"'{TEXT_FILE_NAME}' already exists in '{DATA_DIR}/'. Skipping download.\")\n",
        "\n",
        "# Load Data\n",
        "if os.path.exists(data_file_path):\n",
        "    with open(data_file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.read().split('\\n')\n",
        "\n",
        "    for line in lines[:min(NUM_SAMPLES, len(lines) - 1)]:\n",
        "        try:\n",
        "            # Some lines have a third part (attribution), discard it\n",
        "            input_text, target_text, _ = line.split('\\t')\n",
        "        except ValueError:\n",
        "            # Handle lines without attribution\n",
        "            input_text, target_text = line.split('\\t')\n",
        "\n",
        "        # 2. Preprocess the text\n",
        "        # Normalize English input text: lowercase, add spaces around punctuation, remove special chars\n",
        "        input_text = input_text.lower()\n",
        "        input_text = re.sub(r\"([?.!,¿])\", r\" \\1 \", input_text)\n",
        "        input_text = re.sub(r'[\" \"]+', \" \", input_text)\n",
        "        input_text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", input_text) # Keep basic Latin alphabet and punctuation\n",
        "        input_text = input_text.strip()\n",
        "\n",
        "        # Normalize French target text: lowercase, add spaces around punctuation, remove special chars, add <start> and <end> tokens\n",
        "        target_text = target_text.lower()\n",
        "        target_text = re.sub(r\"([?.!,¿])\", r\" \\1 \", target_text)\n",
        "        target_text = re.sub(r'[\" \"]+', \" \", target_text)\n",
        "        target_text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", target_text)\n",
        "        target_text = target_text.strip()\n",
        "        target_text = '<start> ' + target_text + ' <end>' # Crucial for sequence generation\n",
        "\n",
        "        input_texts.append(input_text)\n",
        "        target_texts.append(target_text)\n",
        "\n",
        "    print(f\"Number of sentence pairs loaded: {len(input_texts)}\")\n",
        "else:\n",
        "    print(\"No data loaded. Cannot proceed with tokenization and model building.\")\n",
        "\n",
        "# Only proceed with tokenization if data was loaded\n",
        "if input_texts:\n",
        "    # Tokenize input (English) and output (French) sequences\n",
        "    input_tokenizer = Tokenizer(filters='')\n",
        "    input_tokenizer.fit_on_texts(input_texts)\n",
        "    input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
        "    input_word_index = input_tokenizer.word_index\n",
        "    input_vocab_size = len(input_word_index) + 1 # +1 for 0-indexed padding token\n",
        "\n",
        "    target_tokenizer = Tokenizer(filters='')\n",
        "    target_tokenizer.fit_on_texts(target_texts)\n",
        "    target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
        "    target_word_index = target_tokenizer.word_index\n",
        "    target_vocab_size = len(target_word_index) + 1 # +1 for 0-indexed padding token\n",
        "\n",
        "    print(f\"English (Input) Vocabulary Size: {input_vocab_size}\")\n",
        "    print(f\"French (Target) Vocabulary Size: {target_vocab_size}\")\n",
        "\n",
        "    # Reverse word indexes for decoding during inference\n",
        "    reverse_input_word_index = dict((i, word) for word, i in input_word_index.items())\n",
        "    reverse_target_word_index = dict((i, word) for word, i in target_word_index.items())\n",
        "\n",
        "    # Pad sequences for batching\n",
        "    max_encoder_seq_length = max(len(seq) for seq in input_sequences)\n",
        "    max_decoder_seq_length = max(len(seq) for seq in target_sequences)\n",
        "\n",
        "    print(f\"Max English (Encoder) sequence length: {max_encoder_seq_length}\")\n",
        "    print(f\"Max French (Decoder) sequence length: {max_decoder_seq_length}\")\n",
        "\n",
        "    # Prepare input_tensor, target_tensor\n",
        "    encoder_input_data = pad_sequences(input_sequences, maxlen=max_encoder_seq_length, padding='post')\n",
        "    decoder_input_data = pad_sequences(target_sequences, maxlen=max_decoder_seq_length, padding='post')\n",
        "\n",
        "    decoder_target_data = np.zeros(\n",
        "        (len(target_sequences), max_decoder_seq_length),\n",
        "        dtype='int32'\n",
        "    )\n",
        "\n",
        "    # Populate decoder_target_data (shifted by one for prediction)\n",
        "    # The target sequence for the decoder is the same as decoder_input_data,\n",
        "    # but shifted one step to the left, and with the <start> token removed.\n",
        "    for i, seq in enumerate(target_sequences):\n",
        "        for j, word_id in enumerate(seq):\n",
        "            if j > 0: # Exclude the <start> token from the target output sequence\n",
        "                decoder_target_data[i, j-1] = word_id\n",
        "\n",
        "    print(\"\\n--- Data Preparation Summary ---\")\n",
        "    print(f\"Shape of Encoder Input Data: {encoder_input_data.shape}\")\n",
        "    print(f\"Shape of Decoder Input Data: {decoder_input_data.shape}\")\n",
        "    print(f\"Shape of Decoder Target Data: {decoder_target_data.shape}\")\n",
        "else:\n",
        "    print(\"Data preparation skipped due to no data loaded.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Task 4: Build Encoder and Decoder using LSTM (Keras) ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Task 4: Building and Training Model (Basic Encoder-Decoder) ---\")\n",
        "\n",
        "if input_vocab_size == 0 or target_vocab_size == 0:\n",
        "    print(\"SKIPPING Task 4: Vocabulary sizes not set. Please ensure Task 3 ran successfully.\")\n",
        "else:\n",
        "    # Encoder Definition\n",
        "    encoder_inputs = Input(shape=(None,), name='encoder_input')\n",
        "    enc_emb = Embedding(input_vocab_size, EMBEDDING_DIM, mask_zero=True, name='encoder_embedding')(encoder_inputs)\n",
        "    encoder_lstm = LSTM(LATENT_DIM, return_state=True, name='encoder_lstm')\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "    encoder_states = [state_h, state_c] # Encoder outputs its final states to be used as decoder initial states\n",
        "\n",
        "    # Decoder Definition\n",
        "    decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
        "    dec_emb = Embedding(target_vocab_size, EMBEDDING_DIM, mask_zero=True, name='decoder_embedding')(decoder_inputs)\n",
        "    decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(target_vocab_size, activation='softmax', name='decoder_output')\n",
        "    final_decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define the model that will turn\n",
        "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "    model = Model([encoder_inputs, decoder_inputs], final_decoder_outputs)\n",
        "\n",
        "    # Compile and train the model\n",
        "    model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nBasic Encoder-Decoder Model Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    print(f\"\\nTraining the basic model for {EPOCHS} epochs...\")\n",
        "    if encoder_input_data.size > 0 and decoder_input_data.size > 0 and decoder_target_data.size > 0:\n",
        "        history = model.fit(\n",
        "            [encoder_input_data, decoder_input_data],\n",
        "            decoder_target_data,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=EPOCHS,\n",
        "            validation_split=0.2 # Use 20% of data for validation\n",
        "        )\n",
        "\n",
        "        print(\"\\nTraining complete. Loss history:\")\n",
        "        for epoch, loss in enumerate(history.history['loss']):\n",
        "            print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {loss:.4f}, Accuracy: {history.history['accuracy'][epoch]:.4f}, Val Loss: {history.history['val_loss'][epoch]:.4f}, Val Accuracy: {history.history['val_accuracy'][epoch]:.4f}\")\n",
        "    else:\n",
        "        print(\"SKIPPING Training: Data not prepared from Task 3.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Task 5: Inference and Evaluation (Basic Encoder-Decoder) ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Task 5: Inference and Evaluation (Basic Encoder-Decoder) ---\")\n",
        "\n",
        "if model is None or reverse_target_word_index is None or not input_texts or not target_texts or \\\n",
        "   encoder_input_data.size == 0 or max_decoder_seq_length == 0 or target_word_index is None:\n",
        "    print(\"SKIPPING Task 5: Dependencies from Task 3 (data, tokenizers) or Task 4 (trained model) not found or are empty.\")\n",
        "else:\n",
        "    # Build inference (sampling) models\n",
        "    # Encoder inference model\n",
        "    encoder_inputs_inf = model.get_layer('encoder_input').input\n",
        "    encoder_lstm_layer_inf = model.get_layer('encoder_lstm')\n",
        "    enc_emb_output_inf = model.get_layer('encoder_embedding')(encoder_inputs_inf)\n",
        "    _, state_h_enc_inf, state_c_enc_inf = encoder_lstm_layer_inf(enc_emb_output_inf)\n",
        "    encoder_model_inf = Model(encoder_inputs_inf, [state_h_enc_inf, state_c_enc_inf])\n",
        "\n",
        "    # Decoder inference model\n",
        "    decoder_inputs_inf = model.get_layer('decoder_input').input\n",
        "    dec_emb_layer_inf = model.get_layer('decoder_embedding')\n",
        "    decoder_lstm_layer_inf = model.get_layer('decoder_lstm')\n",
        "    decoder_dense_layer_inf = model.get_layer('decoder_output')\n",
        "\n",
        "    decoder_state_input_h_inf = Input(shape=(LATENT_DIM,), name='decoder_state_input_h_inf_task5')\n",
        "    decoder_state_input_c_inf = Input(shape=(LATENT_DIM,), name='decoder_state_input_c_inf_task5')\n",
        "    decoder_states_inputs_inf = [decoder_state_input_h_inf, decoder_state_input_c_inf]\n",
        "\n",
        "    dec_emb2_inf = dec_emb_layer_inf(decoder_inputs_inf)\n",
        "    decoder_outputs2_inf, state_h2_inf, state_c2_inf = decoder_lstm_layer_inf(dec_emb2_inf, initial_state=decoder_states_inputs_inf)\n",
        "    decoder_states2_inf = [state_h2_inf, state_c2_inf]\n",
        "    decoder_outputs2_inf = decoder_dense_layer_inf(decoder_outputs2_inf)\n",
        "\n",
        "    decoder_model_inference = Model(\n",
        "        [decoder_inputs_inf] + decoder_states_inputs_inf,\n",
        "        [decoder_outputs2_inf] + decoder_states2_inf\n",
        "    )\n",
        "\n",
        "    def decode_sequence(input_seq):\n",
        "        states_value = encoder_model_inf.predict(input_seq)\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_token_index_start = target_word_index.get('<start>', 0)\n",
        "        if target_token_index_start == 0:\n",
        "            print(\"Warning: '<start>' token not found in target vocabulary. Decoding might fail.\")\n",
        "            return \"\"\n",
        "        target_seq[0, 0] = target_token_index_start\n",
        "\n",
        "        stop_condition = False\n",
        "        decoded_sentence = ''\n",
        "        while not stop_condition:\n",
        "            output_tokens, h, c = decoder_model_inference.predict(\n",
        "                [target_seq] + states_value\n",
        "            )\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "            sampled_word = reverse_target_word_index.get(sampled_token_index, '<unk>')\n",
        "\n",
        "            if sampled_word == '<end>' or len(decoded_sentence.split()) >= max_decoder_seq_length - 1:\n",
        "                stop_condition = True\n",
        "            else:\n",
        "                decoded_sentence += ' ' + sampled_word\n",
        "\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "            states_value = [h, c]\n",
        "        return decoded_sentence.strip()\n",
        "\n",
        "    print(\"\\n--- Translating 5 Test Sentences (Basic Model) ---\")\n",
        "    num_loaded_samples = len(input_texts)\n",
        "    test_indices = [10, 50, 100, 150, 200]\n",
        "    test_indices = [idx for idx in test_indices if idx < num_loaded_samples]\n",
        "\n",
        "    if not test_indices:\n",
        "        print(\"Not enough samples loaded to perform testing. Try increasing NUM_SAMPLES in Task 3.\")\n",
        "    else:\n",
        "        for i in test_indices:\n",
        "            input_seq = encoder_input_data[i:i+1]\n",
        "            translated_sentence = decode_sequence(input_seq)\n",
        "            original_english = input_texts[i]\n",
        "            original_french = target_texts[i].replace('<start> ', '').replace(' <end>', '')\n",
        "\n",
        "            print(f\"\\nInput English: {original_english}\")\n",
        "            print(f\"Original French: {original_french}\")\n",
        "            print(f\"Translated French: {translated_sentence}\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Task 6: Add Basic Attention Mechanism (Optional - Bonus) ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Task 6: Add Basic Attention Mechanism (Optional - Bonus) ---\")\n",
        "\n",
        "if input_vocab_size == 0 or target_vocab_size == 0:\n",
        "    print(\"SKIPPING Task 6: Vocabulary sizes not set. Please ensure Task 3 ran successfully.\")\n",
        "else:\n",
        "    # Encoder Model Definition (with return_sequences=True for attention)\n",
        "    encoder_inputs_att = Input(shape=(None,), name='encoder_input_attention')\n",
        "    enc_emb_att = Embedding(input_vocab_size, EMBEDDING_DIM, mask_zero=True, name='encoder_embedding_attention')(encoder_inputs_att)\n",
        "    encoder_lstm_att = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name='encoder_lstm_attention')\n",
        "    encoder_outputs_att, state_h_enc_att, state_c_enc_att = encoder_lstm_att(enc_emb_att)\n",
        "    encoder_states_att = [state_h_enc_att, state_c_enc_att]\n",
        "\n",
        "    encoder_model_attention_train = Model(encoder_inputs_att, [encoder_outputs_att, state_h_enc_att, state_c_enc_att])\n",
        "    print(\"\\nEncoder Model for Attention (Training) Summary:\")\n",
        "    encoder_model_attention_train.summary()\n",
        "\n",
        "    # Decoder Model Definition with Attention\n",
        "    decoder_inputs_att = Input(shape=(None,), name='decoder_input_attention')\n",
        "    dec_emb_layer_att = Embedding(target_vocab_size, EMBEDDING_DIM, mask_zero=True, name='decoder_embedding_attention')\n",
        "    dec_emb_att = dec_emb_layer_att(decoder_inputs_att)\n",
        "\n",
        "\n",
        "    decoder_lstm_att = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name='decoder_lstm_attention')\n",
        "    decoder_outputs_att, _, _ = decoder_lstm_att(dec_emb_att, initial_state=encoder_states_att)\n",
        "\n",
        "    attention_output = Attention(name='attention_layer')([decoder_outputs_att, encoder_outputs_att])\n",
        "    decoder_concat_input = Concatenate(axis=-1, name='concat_attention')([decoder_outputs_att, attention_output])\n",
        "\n",
        "    decoder_dense_layer_att = Dense(target_vocab_size, activation='softmax', name='decoder_output_attention')\n",
        "    final_decoder_outputs_att = decoder_dense_layer_att(decoder_concat_input)\n",
        "\n",
        "    model_with_attention = Model([encoder_inputs_att, decoder_inputs_att], final_decoder_outputs_att)\n",
        "\n",
        "    model_with_attention.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nModel with Attention Summary (for training):\")\n",
        "    model_with_attention.summary()\n",
        "\n",
        "    print(f\"\\nTraining the model with Attention for {EPOCHS} epochs (if encoder_input_data and decoder_input_data are available)...\")\n",
        "    if encoder_input_data.size > 0 and decoder_input_data.size > 0 and decoder_target_data.size > 0:\n",
        "        # Uncomment the following block to train the model with attention\n",
        "        # Note: This training will overwrite the 'history' variable if you want Task 7 to plot this history\n",
        "        # history = model_with_attention.fit(\n",
        "        #     [encoder_input_data, decoder_input_data],\n",
        "        #     decoder_target_data,\n",
        "        #     batch_size=BATCH_SIZE,\n",
        "        #     epochs=EPOCHS,\n",
        "        #     validation_split=0.2\n",
        "        # )\n",
        "        print(\"Training for model with attention is commented out. Uncomment to run.\")\n",
        "    else:\n",
        "        print(\"SKIPPING Training with attention: Data not prepared from Task 3.\")\n",
        "\n",
        "\n",
        "    # Inference Models for Attention (Conceptual Adaptation of Task 5)\n",
        "    encoder_inf_model_attention = Model(encoder_inputs_att, [encoder_outputs_att, state_h_enc_att, state_c_enc_att])\n",
        "\n",
        "    decoder_state_input_h_inf_att = Input(shape=(LATENT_DIM,), name='decoder_state_input_h_inf_att')\n",
        "    decoder_state_input_c_inf_att = Input(shape=(LATENT_DIM,), name='decoder_state_input_c_inf_att')\n",
        "    decoder_states_inputs_inf_att = [decoder_state_input_h_inf_att, decoder_state_input_c_inf_att]\n",
        "\n",
        "    encoder_outputs_as_input_inf_att = Input(shape=(None, LATENT_DIM,), name='encoder_outputs_inf_att')\n",
        "\n",
        "    dec_emb2_inf_att = dec_emb_layer_att(decoder_inputs_att)\n",
        "\n",
        "    decoder_outputs2_inf_att, state_h2_inf_att, state_c2_inf_att = decoder_lstm_att(dec_emb2_inf_att, initial_state=decoder_states_inputs_inf_att)\n",
        "    decoder_states2_inf_att = [state_h2_inf_att, state_c2_inf_att]\n",
        "\n",
        "    attention_output_inf_att = Attention()([decoder_outputs2_inf_att, encoder_outputs_as_input_inf_att])\n",
        "    decoder_concat_input_inf_att = Concatenate(axis=-1)([decoder_outputs2_inf_att, attention_output_inf_att])\n",
        "\n",
        "    decoder_outputs2_inf_att = decoder_dense_layer_att(decoder_concat_input_inf_att)\n",
        "\n",
        "    decoder_model_attention_inference = Model(\n",
        "        [decoder_inputs_att] + decoder_states_inputs_inf_att + [encoder_outputs_as_input_inf_att],\n",
        "        [decoder_outputs2_inf_att] + decoder_states2_inf_att\n",
        "    )\n",
        "    print(\"\\nDecoder Model with Attention Summary (for inference):\")\n",
        "    decoder_model_attention_inference.summary()\n",
        "    print(\"\\nNote: `decode_sequence` function for attention is more complex and not included in this consolidated block for simplicity. It would need to pass encoder_outputs through the decoding loop.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Task 7: Plotting Loss and Accuracy ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Task 7: Plotting Loss and Accuracy ---\")\n",
        "\n",
        "if history is None:\n",
        "    print(\"SKIPPING Task 7: Model training history ('history' object) not found.\")\n",
        "    print(\"Please ensure Task 4 (or Task 6 training) has been run successfully to generate training history.\")\n",
        "else:\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n--- Observations on Training Performance ---\")\n",
        "    print(\"Based on the plots:\")\n",
        "    print(\"1. Overfitting: Occurs if validation loss starts increasing while training loss continues to decrease significantly, or if validation accuracy plateaus/decreases while training accuracy continues to rise. This indicates the model is memorizing training data.\")\n",
        "    print(\"2. Underfitting: Occurs if both training and validation loss remain high, or accuracy remains low, suggesting the model hasn't learned enough from the data (e.g., due to insufficient epochs, simple model, or high learning rate).\")\n",
        "    print(\"3. Training Stability: Indicated by smooth curves in both loss and accuracy plots. Erratic or noisy curves might suggest issues like an unstable learning rate.\")\n",
        "    print(\"\\n(Please observe your generated plots and fill in specific observations based on your model's performance.)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z9JD9E9A8DbN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}